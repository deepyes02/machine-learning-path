{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "\troot=\"data\",\n",
    "\ttrain=True,\n",
    "\tdownload=True,\n",
    "\ttransform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "\troot=\"data\",\n",
    "\ttrain=False,\n",
    "\tdownload=True,\n",
    "\ttransform=ToTensor(),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N,C,H,W] : torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "\tprint(f\"Shape of X [N,C,H,W] : {X.shape}\")\n",
    "\tprint(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "\tbreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "\t\"cuda\"\n",
    "\tif torch.cuda.is_available()\n",
    "\telse \"mps\"\n",
    "\tif torch.backends.mps.is_available()\n",
    "\telse \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\t\tself.linear_relu_stack = nn.Sequential(\n",
    "\t\t\tnn.Linear(28*28, 512),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(512, 512),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(512, 10)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.flatten(x)\n",
    "\t\tlogits = self.linear_relu_stack(x)\n",
    "\t\treturn logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Model Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "\tsize = len(dataloader.dataset)\n",
    "\tmodel.train()\n",
    "\tfor batch, (X,y) in enumerate(dataloader):\n",
    "\t\tX,y = X.to(device), y.to(device)\n",
    "\n",
    "\t\t# Compute prediction error\n",
    "\t\tpred = model(X)\n",
    "\t\tloss = loss_fn(pred, y)\n",
    "\n",
    "\t\t# Back propagation\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\tif batch % 100 == 0:\n",
    "\t\t\tloss, current = loss.item(), (batch + 1) * len(X)\n",
    "\t\t\tprint(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "\tsize = len(dataloader.dataset)\n",
    "\tnum_batches = len(dataloader)\n",
    "\tmodel.eval()\n",
    "\ttest_loss, correct = 0, 0\n",
    "\twith torch.no_grad():\n",
    "\t\tfor X,y in dataloader:\n",
    "\t\t\tX,y = X.to(device), y.to(device)\n",
    "\t\t\tpred = model(X)\n",
    "\t\t\ttest_loss += loss_fn(pred,y).item()\n",
    "\t\t\tcorrect += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\ttest_loss /= num_batches\n",
    "\tcorrect /= size\n",
    "\tprint(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ......... \n",
      "loss: 2.297779 [   64/60000]\n",
      "loss: 2.286355 [ 6464/60000]\n",
      "loss: 2.261002 [12864/60000]\n",
      "loss: 2.263024 [19264/60000]\n",
      "loss: 2.244042 [25664/60000]\n",
      "loss: 2.211177 [32064/60000]\n",
      "loss: 2.233426 [38464/60000]\n",
      "loss: 2.194184 [44864/60000]\n",
      "loss: 2.189903 [51264/60000]\n",
      "loss: 2.157425 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 29.5%, Avg loss: 2.153087\n",
      "\n",
      "Epoch 2\n",
      " ......... \n",
      "loss: 2.162963 [   64/60000]\n",
      "loss: 2.155674 [ 6464/60000]\n",
      "loss: 2.091150 [12864/60000]\n",
      "loss: 2.114026 [19264/60000]\n",
      "loss: 2.060340 [25664/60000]\n",
      "loss: 1.999056 [32064/60000]\n",
      "loss: 2.035468 [38464/60000]\n",
      "loss: 1.954583 [44864/60000]\n",
      "loss: 1.957252 [51264/60000]\n",
      "loss: 1.882682 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 1.883175\n",
      "\n",
      "Epoch 3\n",
      " ......... \n",
      "loss: 1.914447 [   64/60000]\n",
      "loss: 1.891575 [ 6464/60000]\n",
      "loss: 1.764229 [12864/60000]\n",
      "loss: 1.810673 [19264/60000]\n",
      "loss: 1.697070 [25664/60000]\n",
      "loss: 1.643867 [32064/60000]\n",
      "loss: 1.671017 [38464/60000]\n",
      "loss: 1.573239 [44864/60000]\n",
      "loss: 1.593369 [51264/60000]\n",
      "loss: 1.491364 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 1.514171\n",
      "\n",
      "Epoch 4\n",
      " ......... \n",
      "loss: 1.575061 [   64/60000]\n",
      "loss: 1.551595 [ 6464/60000]\n",
      "loss: 1.395099 [12864/60000]\n",
      "loss: 1.476311 [19264/60000]\n",
      "loss: 1.349838 [25664/60000]\n",
      "loss: 1.344014 [32064/60000]\n",
      "loss: 1.369348 [38464/60000]\n",
      "loss: 1.293931 [44864/60000]\n",
      "loss: 1.327249 [51264/60000]\n",
      "loss: 1.232135 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 1.259763\n",
      "\n",
      "Epoch 5\n",
      " ......... \n",
      "loss: 1.331329 [   64/60000]\n",
      "loss: 1.320820 [ 6464/60000]\n",
      "loss: 1.152566 [12864/60000]\n",
      "loss: 1.265714 [19264/60000]\n",
      "loss: 1.129735 [25664/60000]\n",
      "loss: 1.154121 [32064/60000]\n",
      "loss: 1.189405 [38464/60000]\n",
      "loss: 1.122440 [44864/60000]\n",
      "loss: 1.162744 [51264/60000]\n",
      "loss: 1.081583 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.101582\n",
      "\n",
      "Epoch 6\n",
      " ......... \n",
      "loss: 1.168298 [   64/60000]\n",
      "loss: 1.175729 [ 6464/60000]\n",
      "loss: 0.993072 [12864/60000]\n",
      "loss: 1.132324 [19264/60000]\n",
      "loss: 0.990196 [25664/60000]\n",
      "loss: 1.022455 [32064/60000]\n",
      "loss: 1.074639 [38464/60000]\n",
      "loss: 1.008816 [44864/60000]\n",
      "loss: 1.051744 [51264/60000]\n",
      "loss: 0.984416 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.996267\n",
      "\n",
      "Epoch 7\n",
      " ......... \n",
      "loss: 1.050906 [   64/60000]\n",
      "loss: 1.078788 [ 6464/60000]\n",
      "loss: 0.880782 [12864/60000]\n",
      "loss: 1.040515 [19264/60000]\n",
      "loss: 0.899268 [25664/60000]\n",
      "loss: 0.926319 [32064/60000]\n",
      "loss: 0.996409 [38464/60000]\n",
      "loss: 0.931257 [44864/60000]\n",
      "loss: 0.971858 [51264/60000]\n",
      "loss: 0.916829 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.922163\n",
      "\n",
      "Epoch 8\n",
      " ......... \n",
      "loss: 0.961714 [   64/60000]\n",
      "loss: 1.009019 [ 6464/60000]\n",
      "loss: 0.797744 [12864/60000]\n",
      "loss: 0.973847 [19264/60000]\n",
      "loss: 0.837196 [25664/60000]\n",
      "loss: 0.853999 [32064/60000]\n",
      "loss: 0.939513 [38464/60000]\n",
      "loss: 0.876931 [44864/60000]\n",
      "loss: 0.912556 [51264/60000]\n",
      "loss: 0.866824 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.867502\n",
      "\n",
      "Epoch 9\n",
      " ......... \n",
      "loss: 0.891706 [   64/60000]\n",
      "loss: 0.955731 [ 6464/60000]\n",
      "loss: 0.734145 [12864/60000]\n",
      "loss: 0.923341 [19264/60000]\n",
      "loss: 0.792213 [25664/60000]\n",
      "loss: 0.798541 [32064/60000]\n",
      "loss: 0.895713 [38464/60000]\n",
      "loss: 0.837969 [44864/60000]\n",
      "loss: 0.867446 [51264/60000]\n",
      "loss: 0.827884 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.825546\n",
      "\n",
      "Epoch 10\n",
      " ......... \n",
      "loss: 0.835100 [   64/60000]\n",
      "loss: 0.912513 [ 6464/60000]\n",
      "loss: 0.683803 [12864/60000]\n",
      "loss: 0.883822 [19264/60000]\n",
      "loss: 0.758049 [25664/60000]\n",
      "loss: 0.755302 [32064/60000]\n",
      "loss: 0.860321 [38464/60000]\n",
      "loss: 0.808830 [44864/60000]\n",
      "loss: 0.832153 [51264/60000]\n",
      "loss: 0.796315 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.792113\n",
      "\n",
      "Epoch 11\n",
      " ......... \n",
      "loss: 0.788082 [   64/60000]\n",
      "loss: 0.875876 [ 6464/60000]\n",
      "loss: 0.642808 [12864/60000]\n",
      "loss: 0.852243 [19264/60000]\n",
      "loss: 0.730762 [25664/60000]\n",
      "loss: 0.721021 [32064/60000]\n",
      "loss: 0.830328 [38464/60000]\n",
      "loss: 0.785971 [44864/60000]\n",
      "loss: 0.803680 [51264/60000]\n",
      "loss: 0.769704 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.764456\n",
      "\n",
      "Epoch 12\n",
      " ......... \n",
      "loss: 0.748069 [   64/60000]\n",
      "loss: 0.843484 [ 6464/60000]\n",
      "loss: 0.608713 [12864/60000]\n",
      "loss: 0.826414 [19264/60000]\n",
      "loss: 0.708018 [25664/60000]\n",
      "loss: 0.693371 [32064/60000]\n",
      "loss: 0.803908 [38464/60000]\n",
      "loss: 0.767160 [44864/60000]\n",
      "loss: 0.779983 [51264/60000]\n",
      "loss: 0.746542 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.740770\n",
      "\n",
      "Epoch 13\n",
      " ......... \n",
      "loss: 0.713474 [   64/60000]\n",
      "loss: 0.814211 [ 6464/60000]\n",
      "loss: 0.579683 [12864/60000]\n",
      "loss: 0.804794 [19264/60000]\n",
      "loss: 0.688506 [25664/60000]\n",
      "loss: 0.670622 [32064/60000]\n",
      "loss: 0.779876 [38464/60000]\n",
      "loss: 0.750957 [44864/60000]\n",
      "loss: 0.759835 [51264/60000]\n",
      "loss: 0.725878 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.719892\n",
      "\n",
      "Epoch 14\n",
      " ......... \n",
      "loss: 0.683130 [   64/60000]\n",
      "loss: 0.787390 [ 6464/60000]\n",
      "loss: 0.554627 [12864/60000]\n",
      "loss: 0.786087 [19264/60000]\n",
      "loss: 0.671387 [25664/60000]\n",
      "loss: 0.651632 [32064/60000]\n",
      "loss: 0.757618 [38464/60000]\n",
      "loss: 0.736604 [44864/60000]\n",
      "loss: 0.742233 [51264/60000]\n",
      "loss: 0.707021 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.701106\n",
      "\n",
      "Epoch 15\n",
      " ......... \n",
      "loss: 0.656347 [   64/60000]\n",
      "loss: 0.762566 [ 6464/60000]\n",
      "loss: 0.532641 [12864/60000]\n",
      "loss: 0.769808 [19264/60000]\n",
      "loss: 0.656169 [25664/60000]\n",
      "loss: 0.635577 [32064/60000]\n",
      "loss: 0.736756 [38464/60000]\n",
      "loss: 0.723660 [44864/60000]\n",
      "loss: 0.726765 [51264/60000]\n",
      "loss: 0.689623 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.684033\n",
      "\n",
      "Epoch 16\n",
      " ......... \n",
      "loss: 0.632529 [   64/60000]\n",
      "loss: 0.739757 [ 6464/60000]\n",
      "loss: 0.513305 [12864/60000]\n",
      "loss: 0.755246 [19264/60000]\n",
      "loss: 0.642683 [25664/60000]\n",
      "loss: 0.621759 [32064/60000]\n",
      "loss: 0.717168 [38464/60000]\n",
      "loss: 0.712082 [44864/60000]\n",
      "loss: 0.713059 [51264/60000]\n",
      "loss: 0.673559 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.668425\n",
      "\n",
      "Epoch 17\n",
      " ......... \n",
      "loss: 0.611354 [   64/60000]\n",
      "loss: 0.718858 [ 6464/60000]\n",
      "loss: 0.496182 [12864/60000]\n",
      "loss: 0.741961 [19264/60000]\n",
      "loss: 0.630708 [25664/60000]\n",
      "loss: 0.609797 [32064/60000]\n",
      "loss: 0.698844 [38464/60000]\n",
      "loss: 0.701815 [44864/60000]\n",
      "loss: 0.701056 [51264/60000]\n",
      "loss: 0.658519 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.654086\n",
      "\n",
      "Epoch 18\n",
      " ......... \n",
      "loss: 0.592317 [   64/60000]\n",
      "loss: 0.699628 [ 6464/60000]\n",
      "loss: 0.480885 [12864/60000]\n",
      "loss: 0.729726 [19264/60000]\n",
      "loss: 0.619825 [25664/60000]\n",
      "loss: 0.599295 [32064/60000]\n",
      "loss: 0.681549 [38464/60000]\n",
      "loss: 0.692734 [44864/60000]\n",
      "loss: 0.690670 [51264/60000]\n",
      "loss: 0.644410 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.640926\n",
      "\n",
      "Epoch 19\n",
      " ......... \n",
      "loss: 0.575180 [   64/60000]\n",
      "loss: 0.682063 [ 6464/60000]\n",
      "loss: 0.467213 [12864/60000]\n",
      "loss: 0.718380 [19264/60000]\n",
      "loss: 0.610022 [25664/60000]\n",
      "loss: 0.590172 [32064/60000]\n",
      "loss: 0.665351 [38464/60000]\n",
      "loss: 0.684818 [44864/60000]\n",
      "loss: 0.681656 [51264/60000]\n",
      "loss: 0.631300 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.628843\n",
      "\n",
      "Epoch 20\n",
      " ......... \n",
      "loss: 0.559729 [   64/60000]\n",
      "loss: 0.666079 [ 6464/60000]\n",
      "loss: 0.454902 [12864/60000]\n",
      "loss: 0.707876 [19264/60000]\n",
      "loss: 0.601067 [25664/60000]\n",
      "loss: 0.582175 [32064/60000]\n",
      "loss: 0.650245 [38464/60000]\n",
      "loss: 0.678068 [44864/60000]\n",
      "loss: 0.673852 [51264/60000]\n",
      "loss: 0.619105 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.617761\n",
      "\n",
      "Epoch 21\n",
      " ......... \n",
      "loss: 0.545728 [   64/60000]\n",
      "loss: 0.651435 [ 6464/60000]\n",
      "loss: 0.443773 [12864/60000]\n",
      "loss: 0.697998 [19264/60000]\n",
      "loss: 0.592874 [25664/60000]\n",
      "loss: 0.575117 [32064/60000]\n",
      "loss: 0.636195 [38464/60000]\n",
      "loss: 0.672324 [44864/60000]\n",
      "loss: 0.667154 [51264/60000]\n",
      "loss: 0.607641 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.607600\n",
      "\n",
      "Epoch 22\n",
      " ......... \n",
      "loss: 0.532984 [   64/60000]\n",
      "loss: 0.638008 [ 6464/60000]\n",
      "loss: 0.433590 [12864/60000]\n",
      "loss: 0.688640 [19264/60000]\n",
      "loss: 0.585342 [25664/60000]\n",
      "loss: 0.568813 [32064/60000]\n",
      "loss: 0.623168 [38464/60000]\n",
      "loss: 0.667558 [44864/60000]\n",
      "loss: 0.661389 [51264/60000]\n",
      "loss: 0.596816 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.598274\n",
      "\n",
      "Epoch 23\n",
      " ......... \n",
      "loss: 0.521226 [   64/60000]\n",
      "loss: 0.625665 [ 6464/60000]\n",
      "loss: 0.424241 [12864/60000]\n",
      "loss: 0.679819 [19264/60000]\n",
      "loss: 0.578215 [25664/60000]\n",
      "loss: 0.562956 [32064/60000]\n",
      "loss: 0.611088 [38464/60000]\n",
      "loss: 0.663670 [44864/60000]\n",
      "loss: 0.656504 [51264/60000]\n",
      "loss: 0.586540 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.589701\n",
      "\n",
      "Epoch 24\n",
      " ......... \n",
      "loss: 0.510281 [   64/60000]\n",
      "loss: 0.614318 [ 6464/60000]\n",
      "loss: 0.415654 [12864/60000]\n",
      "loss: 0.671445 [19264/60000]\n",
      "loss: 0.571379 [25664/60000]\n",
      "loss: 0.557526 [32064/60000]\n",
      "loss: 0.599896 [38464/60000]\n",
      "loss: 0.660599 [44864/60000]\n",
      "loss: 0.652323 [51264/60000]\n",
      "loss: 0.576824 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.581815\n",
      "\n",
      "Epoch 25\n",
      " ......... \n",
      "loss: 0.500078 [   64/60000]\n",
      "loss: 0.603900 [ 6464/60000]\n",
      "loss: 0.407731 [12864/60000]\n",
      "loss: 0.663445 [19264/60000]\n",
      "loss: 0.564716 [25664/60000]\n",
      "loss: 0.552469 [32064/60000]\n",
      "loss: 0.589532 [38464/60000]\n",
      "loss: 0.658265 [44864/60000]\n",
      "loss: 0.648722 [51264/60000]\n",
      "loss: 0.567543 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.574550\n",
      "\n",
      "Epoch 26\n",
      " ......... \n",
      "loss: 0.490490 [   64/60000]\n",
      "loss: 0.594303 [ 6464/60000]\n",
      "loss: 0.400425 [12864/60000]\n",
      "loss: 0.655694 [19264/60000]\n",
      "loss: 0.558282 [25664/60000]\n",
      "loss: 0.547621 [32064/60000]\n",
      "loss: 0.579955 [38464/60000]\n",
      "loss: 0.656482 [44864/60000]\n",
      "loss: 0.645540 [51264/60000]\n",
      "loss: 0.558656 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.567836\n",
      "\n",
      "Epoch 27\n",
      " ......... \n",
      "loss: 0.481481 [   64/60000]\n",
      "loss: 0.585398 [ 6464/60000]\n",
      "loss: 0.393658 [12864/60000]\n",
      "loss: 0.648385 [19264/60000]\n",
      "loss: 0.551939 [25664/60000]\n",
      "loss: 0.542943 [32064/60000]\n",
      "loss: 0.571091 [38464/60000]\n",
      "loss: 0.655237 [44864/60000]\n",
      "loss: 0.642691 [51264/60000]\n",
      "loss: 0.550124 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.561633\n",
      "\n",
      "Epoch 28\n",
      " ......... \n",
      "loss: 0.472943 [   64/60000]\n",
      "loss: 0.577157 [ 6464/60000]\n",
      "loss: 0.387366 [12864/60000]\n",
      "loss: 0.641281 [19264/60000]\n",
      "loss: 0.545811 [25664/60000]\n",
      "loss: 0.538387 [32064/60000]\n",
      "loss: 0.562899 [38464/60000]\n",
      "loss: 0.654406 [44864/60000]\n",
      "loss: 0.640337 [51264/60000]\n",
      "loss: 0.542006 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.555896\n",
      "\n",
      "Epoch 29\n",
      " ......... \n",
      "loss: 0.464825 [   64/60000]\n",
      "loss: 0.569572 [ 6464/60000]\n",
      "loss: 0.381435 [12864/60000]\n",
      "loss: 0.634519 [19264/60000]\n",
      "loss: 0.539795 [25664/60000]\n",
      "loss: 0.533958 [32064/60000]\n",
      "loss: 0.555272 [38464/60000]\n",
      "loss: 0.653926 [44864/60000]\n",
      "loss: 0.638222 [51264/60000]\n",
      "loss: 0.534227 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.550576\n",
      "\n",
      "Epoch 30\n",
      " ......... \n",
      "loss: 0.457132 [   64/60000]\n",
      "loss: 0.562519 [ 6464/60000]\n",
      "loss: 0.375950 [12864/60000]\n",
      "loss: 0.628102 [19264/60000]\n",
      "loss: 0.533851 [25664/60000]\n",
      "loss: 0.529601 [32064/60000]\n",
      "loss: 0.548194 [38464/60000]\n",
      "loss: 0.653773 [44864/60000]\n",
      "loss: 0.636294 [51264/60000]\n",
      "loss: 0.526735 [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.545631\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "for t in range(epochs):\n",
    "\tprint(f\"Epoch {t+1}\\n ......... \")\n",
    "\ttrain(train_dataloader, model, loss_fn, optimizer)\n",
    "\ttest(test_dataloader, model, loss_fn)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precited 'x', actual : 'x'\n"
     ]
    }
   ],
   "source": [
    "##### App that makes predictions\n",
    "#LOading model\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "\t\t\"x\"\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x,y = test_data[0][0], test_data[0][1]\n",
    "\n",
    "with torch.no_grad():\n",
    "\tx = x.to(device)\n",
    "\tpred = model(x)\n",
    "\tpredicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "\t\n",
    "\tprint(f\"Precited '{predicted}', actual : '{actual}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
